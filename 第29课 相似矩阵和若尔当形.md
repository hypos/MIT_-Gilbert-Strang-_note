何谓相似？

两个矩阵相似意味着什么？

---

正定从何而来？

正定阵来自最小二乘法，大量的物理问题需要用长方形矩阵描述，最小二乘法的关键在于矩阵$A^TA$，希望证明$A$是一个正定阵。

假设$A$是__正定__的，意味差$A$是__对称阵__，即为__对称正定阵__。$A$__逆矩阵__的__特征值__等于$A$阵__特征值__的__倒数__，$A$__逆矩阵__也是__正定的__，因为$A$特征值全为正数，所以倒数也为正数

$A$和$B$都是正定的可得，$C=A+B$也是正定的
$$
x^TAx>0;x^TBx>0 \to x^T(A+B)>0
$$


证明最小二乘法为正定的：
$$
A_{mn};m\ne n \to B=A^TA，B为方阵且对称\\
x^T\underbrace{A^TA}_{B}x=(x^TA^T)(Ax)=(Ax)^T(Ax)=||Ax||^2\ge0
$$
如果__零空间__没有其它向量则，$r=n$，矩阵$A$__各列线性无关__，确保$A^TA$正定，如果$A^TA$可逆，最小二乘方程将存在最优解，所以$A^TA$为正定阵

---

$A$和$B$为__相似阵__，$n\times n$，存在某个__可逆矩阵__$m$使得$B$可以表示为$A$ 
$$
B=m^{-1}Am
$$


>
>
>例：$A$有无关的特征向量，也就是存在特征向量矩阵$S$ 
>$$
>S^{-1}\Lambda S,\Lambda为简洁的对角阵
>$$
>按照新说活，$A$相似于$\Lambda$，矩阵$A$的所有相似阵里面$\Lambda$是最好的
>$$
>A=\begin{bmatrix}2&1\\1&2\end{bmatrix};
>\Lambda=\begin{bmatrix}3&0\\0&1\end{bmatrix}\\
>
>m=\begin{bmatrix}1&4\\0&1\end{bmatrix};
>m^{-1}=\begin{bmatrix}1&-4\\0&1\end{bmatrix}\\
>
>m^{-1}Am=\begin{bmatrix}1&-4\\0&1\end{bmatrix}
>\begin{bmatrix}2&1\\1&2\end{bmatrix}
>\begin{bmatrix}1&4\\0&1\end{bmatrix}=
>\begin{bmatrix}1&-4\\0&1\end{bmatrix}
>\begin{bmatrix}2&9\\1&6\end{bmatrix}=
>\begin{bmatrix}-2&-15\\1&6\end{bmatrix}=B
>$$
>$A$



*** $A$与$B$具有相同的__特征值__，因为__相似__    __(重要性质)__

$\lambda=3,1$，通过迹来验证，$A_{迹}=2+2=4;B_{迹}=-2+6=4$  



> 例：证明相似阵特征值相同这一重要性质
> $$
> m=\begin{bmatrix}3&7\\0&1\end{bmatrix};
> m^{-1}=\begin{bmatrix}1&7\\0&3\end{bmatrix}\\
> 
> Ax=\lambda x,A的特征值\lambda\\
> 
> B=m^{-1}Am,B的特征值？\\
> 
> Ax=\lambda x \to Amm^{-1}x=\lambda x 
> \underbrace{\to}_{同时左乘m^{-1}}m^{-1}Amm^{-1}x= \lambda m^{-1}x\\
> 
> \to (m^{-1}Am)m^{-1}x=\lambda m^{-1}x \to Bm^{-1}x=\lambda m^{-1}x\\
> 
> \to Bx=\lambda x \to 表明\lambda是B的一个特征值，但特征向量并不相等
> $$
> $B$的特征向量等于$m^{-1}$乘以矩阵$A$的特征向量
>
>





---

对角阵的特征向量分别是$(1,0),(0,1)$，特征值 不变，相似矩阵的特征值保持不变

相似矩阵特征向量可能不再线性无关，矩阵可能无法对角化(坏情况：$\lambda_1=\lambda_2$，矩阵可能无法对角化)



$4I=\begin{bmatrix}4&0\\0&4\end{bmatrix}$除外，其余矩阵属于另一类，该阵只和自己__相似__，意味着__只有一个特征向量__，它将无法对角化，把1改为$10$或$10^6$，同样可以找到$m$使它和原矩阵相似，为1时，是这类矩阵最好的一个，称为__若尔当标准型__，它是最简洁，最接近对角阵的一个
$$
\underbrace{
    \left[
        \begin{array}{ccc|c}
            0&1&0&0\\0&0&1&0\\0&0&0&0\\\hline 0&0&0&0
        \end{array}
    \right]
}_{A}\\
\lambda=0,0,0,0\\
2个线性无关的特征向量\\
零空间维数等于2(N(A)=2)\\
若尔当分块3\times3,1\times1
$$

$$
\underbrace{
	\begin{bmatrix}0&1&7&0\\0&0&1&0\\0&0&0&0\\0&0&0&0\end{bmatrix}
}_{B}\\
\lambda=0,0,0,0\\
2个线性无关的特征向量\\
N(A)=2\\
$$

$A$和$B$相似。

注意对角线上方的1,每增加一个1特征向量就减少1个。



例：若尔当分块$2\times2,2\times2$
$$
\left[
    \begin{array}{cc|cc}
    	0&1&0&0\\0&0&0&0\\\hline0&0&0&1\\0&0&0&0
    \end{array}
\right]
$$
若尔当分块：$J_i$表示$i$阶的若尔当块，每个方阵$A$都相似于一个若尔当阵$J$，就是由若尔当块构成的矩阵

